# 计算机科学速成课

### “计算”与“开关”的进化

1. 最早的computer是一个职业，后来出现了像是Step Reckoner这样的简单机械。
   1. 不过人们还是更喜欢用Computer们编辑的计算表格书，查表找计算结果……
   2. 后来战争中为了计算炮弹轨迹还出现了射程表格——环境、角度都计算在内。当然，每一个新设计的大炮或者炮弹都必须重新计算一张表格。
   3. 差分机、分析机（仅仅有概念但是无法实际制造）可以计算多项式、三角函数这样的东西，并且具备了一定的灵活程度，具备“内存”甚至一个原始打印机。这种自动化的计算机器理念是计算机的雏形。
   4. 美国的人口普查中，为了节省效率，出现了打孔的计算器，通过打孔与否代表“状态”如已婚或者未婚，然后交给机器自动处理。 后来这种机器商用化，IBM诞生。
2. 所谓的乘除不过就是减法/加法+循环反复的结果。 
3. 打孔计算器+继电器=？
   1. 但是早期的机械继电器容易磨损、速度很慢，庞大、很难维护（吸引虫子BUG）。
4. 电子管：二极管+控制电路=三极管。
   1. 早期的三极管是由纯电路做出来的。
   2. 没有机械移动的组件，电子管继电器时代到来——从机电到电子。
   3. 第一台“可编程”计算机用于破译电码。真正的通用可编程计算机则是宾夕法尼亚大学的ENIAC。每秒5000次的计算。
   4. 电子管庞大但是还是容易坏。
5. 晶体管：半导体
   1. 稳定、高速、体积很小的开关。
   2. 摩尔定律的时代开启。硅谷的起源。

### 如何用开关构建“逻辑”和“计算”

1. 晶体管是可以不同等级的电流通过的——最早设计过3进制、五进制的计算机，但是都面临了一个问题——扰动和不稳定，如果信号被干扰，那么很容易让传输的信息出现错误，二进制就更加稳定。
   1. 而另外重要的一点就是——当时Bool代数已经成熟，逻辑可以使用“真假”以及逻辑运算去衡量，真假对应的就是晶体管导通/关断的两个状态。
   2. 通过晶体管的组合，创造了一些称为“门”的基础电路（晶体管的并联/串联生成OR/AND逻辑）。通过这些基础的逻辑，以及Bool逻辑学的知识，能够创造出更加复杂的逻辑——数字电路的诞生。
   3. 数电本身就是底层电路+逻辑的一次“抽象”的过程，门被创造后，我们不需要再去关注下层，而只需要用“门”这样的抽象“积木”就可以创造逻辑。
2. 数据本身可以使用二进制的方法储存。不同类型的数据需要不同的“标准”或者说“方法”，规定好了之后数据才能被不同人和公司使用。
   1. 浮点数 IEE754标准：通常 正负+储存数据+有效位数+指数。
   2. 字符和文字：标准同样很多，ASCII码就是很常用的。中文和日文的编码8位不够用，需要用16位，然后Unicode出来统一管理了全部编码标准。

### CPU的诞生

1. ALU算术逻辑运算单元：**从逻辑到算术**
   1. 算术运算包含了两种类型：两个数字的相加以及对某个数字增量。
   2. 加法器：单个位上的运算可以看作是一个“异或XOR”运算，同时使用一个“与”门计算来计算是否会进位：用XOR和AND组合，输入两个位，输出是 总和 以及 进位信息 —— 抽象出了一个“半加器”。输入三个位（只需要组合两个half adder就可以了）则组成了一个全加器。由此逻辑门构成了算术运算。
      1. 例如一个8位的加法，只需要每一位相加就可以了（1个半加器和7个全加器）。
      2. 溢出：最后一位上出现进位，则说明溢出了。
   3. 现代一般使用的是超前进位加法器电路完成加法。
      1. 过去简单的ALU是没有乘法器的。现代出现了专门处理乘除甚至卷积运算的单元，集成在专业的嵌入式设备中。
   4. ALU进行了抽象之后形成了一个V的符号，一般一个加法器由 n位输入、n位输出、溢出、加/减法符号、两个数字是否相等的判断。
2. 储存器，内存：
   1. RAM：随机储存器
   2. 数字电路中的锁存器就是最基本的储存单元：输入信号+锁存（允许写入内存的信号）信号=一位的内存
   3. 内存的矩阵：地址唯一指定一个内存单元。行地址和列地址组合选择。
      1. 这样的矩阵8个并联，一次性可以读取或者写入8位数据。现代内存的矩阵本质也是矩阵的不断抽象和层层嵌套
      2. 这种内存最重要的特性就是（通过地址总线）”随时可以访问到任何位置“——这就是RAM。
3. Central Processing Unit
   1. 把”程序与指令“也记录为一种数据：操作码+地址的组合。从内存中取出指令放置在寄存器中。
   2. 控制单元的任务就是：取指令、解码、执行。循环往复。控制单元是CPU执行命令的核心，负责获取指令，调用运算、储存以及使用寄存器完成特定的指令。
   3. 时钟信号让控制单元每个步骤按照固定的频率执行。通过超频或者降频可以调控电量和性能。
4. CPU指令和编程：指令的组合就是编程。
   1. 除了读取内存数值、加减法运算会自动按照地址顺序执行之外，还有类似JUMP或者条件判断（简单的比如负数判断）这种可以改变指令读取顺序的。
   2. 可变指令长度——现代指令集为了扩充数据长度、指令种类的一种设计。
5. 最早的CPUIntel 4004 46个指令集，4位的内存。
6. 高级CPU设计：为不同的场景设计专用的计算单元
   1. 现代的单元通常包含了数千条指令
   2. 总线、Cache设计为现代计算机高速传输数据提供了路径和可能。
   3. 流水线：每一步的工作地点不一样，可以用流水线的方法压缩，取址不一定要等到上一个指令完全结束，只需要上一个取值结束就行了。
   4. 并行/多个指令流：充分利用多个CPU。 

 

### 编程

- 编程是指令的组合，通过一个可以反复“书写”的控制面板进行输入。

1. 什么是编程？在博物馆中看过的通过打孔来让织布机纺织出特定的图案、美国人口统计机器通过打孔格式来确定个人信息、音乐盒上通过定制突起获得音乐。到后来可插拔的编程。

   1. 直到内存的出现，让程序可以被储存。程序和数据保存在内存中，就是冯诺依曼结构的基本想法。
   2. 当时的输入和输出都是打孔纸，或者使用面板编程——用开关进行编程。

2. 语言的发展历史：

   1. 机器语言=机器唯一能够理解的语言，二进制。

   > 伪代码出现的时间很早，最早需要从伪代码转化到机器语言，因此伪代码的存在显得非常重要。

   2. 汇编Assembly语言=机器语言上加上助记符号，直接转换成为机器语言。
   3. 1952年诞生了第一个编译器，从此人们开始尝试编程语言——计算机从“计算”走向了“程序”，“Make write programs easier”的想法让初代的程序员开始创造新的编程语言。
      1. FORTRAN，IBM，“come from lazy”.
      2. 1950前的代码只能跑在特定的机器上，高级编程语言的特点则是需要能够跑在不同的机器上。
      3. 高级语言本质上是对机器语言的抽象（clever abstraction）。不同的抽象方法让语言在某个方面具备了独特的优势，语言的设计一方面面向机器底层，另一方面面向用户和现实世界。脱离了底层的细节，程序员能够创造更多更复杂的可能性。
         1. 当然，很多的编程语言内也有类似于类和函数这样的抽象方法。
         2. 这种抽象是现代合作编程的基础。

3. 算法和数据结构

   1. 算法：有限步骤解决问题的方法。
   2. 复杂度：输入数据大小和运行的时间、空间上的关系。
   3. 图搜索：Dijkstra算法，加权的图中，使用标记节点的方法寻找最小路径。
   4. 数据结构是算法的载体，二者不可能分离去谈。数据结构设计本质是服务于业务的逻辑，让数据排列成使用者希望以及计算机便于处理的方式。计算机处理的方式就是“算法”的一部分，也是算法最基本要完成的任务，正确快速的读出想要的数据，才能够使用算法进一步的处理。
   5. 数据结构通常包含在了高级语言的标准库中。

### 计算机通识

1. 阿兰-图灵
   1. 图灵机：一台假想设备，可以解决一切计算问题的假想。
   2. 图灵机模型：可以解决任何计算问题，但是不是所有的问题都可以是计算问题。
   3. 图灵设计出了一中破译机器，自动遍历可能的方法去尝试解码。
   4. 开启了AI的研究：图灵测试——“验证码”的原型。
2. 软件工程
   1. 函数层继续向工程项目去抽象，封装，隐藏内部复杂性，形成了类。这就是面向对象的编程。
   2. 这种抽象让软件的开发可以被分解成为一层层的工作，让软件工程得以称为一门学问。
   3. IDE
   4. 代码规范：README、注释、文档，这些可以提高代码的复用性。
   5. commit，master，回滚，这些本身最重要的其实是为了团队编程而准备的。
3. 集成电路和摩尔定律
   1. 从分立元器件到集成电路：对电路的封装就形成了集成电路，IC开始代替分立元器件，相应，PCB也随之诞生。
   2. 元器件的制作使用的技术称为“光刻”。
   3. 摩尔定律：这个人演示Intel的两个创始人之一。
   4. 现代集成电路的设计是通过VISI软件。
   5. 当前的两个继续缩小的瓶颈：量子隧穿效应、光的波长极限。
4. 操作系统：
   1. 操作系统的诞生起源于“如何充分利用一台机器，让机器自己知道执行什么任务”。
      1. 批处理诞生
   2. 能够兼容不同的底层硬件而不需要程序员了解硬件细节
      1. 诞生了设备驱动程序
   3. 多人操作一个计算机的需求、不同进程之间的最大程度利用CPU，做到一定程度上的并行处理。
      1. 不同的线程又独立的内存。
      2. 为了便于管理内存使用情况，使用了虚拟内存。用户不需要知道计算机存在了哪里，这个转换可以让机器自己去算——动态内存分配。内存在用户这似乎连续，只有计算机知道它真正的物理位置。
   4. 终端：一个CPU与多个终端。
      1. 分时操作系统：重要是不同用户之间的权限，数据安全。
      2. UNIX诞生——一个紧凑内核，除掉了多余的东西。
   5. 家用电脑和Windows。
      1. 现代的操作系统虽然不再会需要多人一起使用，但是还是保存了内存保护机制，现在的作用主要是多个程序能够轻松的并行处理。
5. 内存和存储设备：

   1. 技术不停的进步，出现过用磁芯、声波等介质制作的存储设备。
   2. 磁盘通过堆叠可以大量存储数据。储存设备不同的成本和容量速度混合使用，称之为“储存结构”。 
   3. 软盘、光盘CD、DVD——使用的是光学的反射。
   4. 固态SSD出现。
6. 文件和文件管理

   1. 文件的后缀决定的是“如何读取这个文件的数据”。
   2. 为了记录文件的位置和大小——在计算机中一般存在目录，记录全部文件的储存位置信息和大小信息等，OS中也存在文件管理系统。
   3. 文件大小会增长，因此系统会为这个文件的增长分配空闲的块使用。一个文件可能会被存在很多的块里。系统会自动做碎片整理，把多个块进行整理合并。
   4. 文件树中目录的信息中存储了目录下文件的目录文件，这样让文件系统拥有了“深度”。
7. 压缩技术：无损压缩和有损压缩技术

   1. 理解了数据的本质，压缩就能够比较简单了。

### 计算机交互的发展

1. 命令行界面：Input by human——人机交互的进化

   1. 最早的操作都是直接在电路和机械上做的。后来由磁带和打孔（答题卡？）代替。
   2. 键盘1950出现，布局采用了打字机中常用的一种qwert布局。出现了一种职业——专业打字员。命令行交互出现。当然，最早不用屏幕而是打字机实现的这种交互。
      1. 交互的出现同时，交互的游戏也被发明了。

2. 图形化界面&屏幕

   1. 高分辨率的屏幕是图形化界面的前提。阴极管CRTs屏幕，刷新率和分辨率都很低，扫描来呈像。而当时LED显示屏的发展受到了存储的制约。

   2. > 这么看来过去每一次的创新进步在短时间内似乎一下子变成了稀疏平常。

   3. 用文字表示出图像——ASCII拓宽了字符，可以绘制“文字符号”。

   4. 图形符号最初的绘制方法：就像是海龟画图那样，这种方法绘制的矢量图非常节省内存，图像完全用线组成。太空大战就是用这个做的。

   5. 显示器有了8bit深度的图，灰度图可以绘制。位图诞生，同时图形化界面也诞生。

10. 冷战太空竞备中，对于太空中的导航设备的需求加速了计算机的发展。之后则是出现了个人计算机，促进了计算机的繁荣发展。
11. 随着个人计算机的出现，图形化的界面逐步发展，出现了成熟的图形化桌面体系。所见即所得的交互设计概念气蒙了了现代个人计算机。
    1. WIMP是最初的GUI
    2. Windows1.0基于DOS，虽然不美观，但市场占有率很高。随后Windows95的GUI彻底走向了成熟。
    3. 也从此，交互设计成为软件设计非常重要的一环。
12. 3D图形：计算机3D图形本质上还是2D图形，是3D经过投影计算得到的2D图形。
    1. Polygon多面体是一个个小的三角构成的，三点能够确定一个平面——”面“。
    2. 填充多面体的技术成为”渲染“。
       1. 最早的渲染：扫描渲染，在如今低配电脑上很常见，锯齿明显。+抗锯齿技术：在锯齿边缘做一些模糊处理，就能够看起来柔和一点。
       2. 画家渲染：从远到近的渲染
       3. 深度缓冲：预先加载距离，然后
    3. 灯光：计算每一个面的朝向，然后计算出每一个面的明暗。
       1. 平面着色
    4. 纹理：从纹理文件中查找对应像素给多面体着色。



### 互联网的时代

1. 早期的网络目的是共享如内存等资源。——以太网比较流行，当时的以太网是一种有线通讯网络，当时网络中的一些如带宽概念已经出现了。
   1. 指数退避：让计算机等待指数的时间来避免通讯冲突。
   2. 交换机：地址的交换——将网络分解成更小的部分，交换机负责地址交换。
   3. 更多的交换机为了能够正常使用，出现了”路由“。网络的好处在于”**分布**“，没有中心意味着总能找到一条通讯的路径。而路由器的作用就是帮助找到这个路径。
   4. 数据包：把报文分解成小的数据包，避免阻塞。
2. 互联网：
   1. TCP/IP协议：保证传输的成功
   2. 网络越拥堵，一般传输的成功率越低。
   3. 访问网络需要：ip+端口号=DNS域名。
   4. 七层模型——象征了网络连接从物理到应用的五次抽象。
3. 万维网：WWW
   1. 连接世界的网络，通过浏览器来访问其中的数以万计的服务器。
   2. 超文本的概念诞生时候甚至还没有显示器。
   3. 网页之间有一个唯一url，而通过超文本互相连接访问。
   4. HTTP协议是从服务器获取一个url对应的网页的协议。网页会在个人的浏览器中被渲染。
      1. HTML语言：超文本标记语言。最早只有超链接，现在HTML5已经有了上百种标记。
   5. 浏览器：搜索和排序算法，以及链接的爬虫——这一点上拉扯过很长时间。
      1. 浏览器的时代，信息开始被商业公司所重视。
4. 计算机安全
   1. 计算机的安全包括了：数据、权限、系统本身的安全。
   2. 验证密码的三种方式：怎么证明是你本人？
      1. What you know
      2. Who you are 
      3. What you have
   3. 计算机的安全主要是预防”攻击“，攻击手段决定了安全保护手段。
   4.  多层权限的安全模型
   5. 安全软件：安全内核一般来说都是开源的——由安全大会。
   5. 黑客攻击：包括了利用系统漏洞、网络诈骗等手段。
5. 加密：不存在100%的安全
   1. 英格玛替换加密：多层的转换。最后被图灵破解。
   2. 1977IBM数据标准加密DES，2001AES，最高256位的密钥。性能和安全性的权衡。
   3. 单向函数：迪菲-赫尔曼密钥交换，采用幂模运算——一次幂运算和一次取模运算，这种方法正向容易逆向难。
      1. 将基数和取模的值作为公钥，两个用户分别将指数作为自己的钥。运算后发送结果，对结果进行幂运算，指数是自己的密钥就能够得到一个相同的结果 。对称加密
      2. 非对称密钥：每人有两个钥匙。




### AI人工智能时代

1. 分类：特征数据训练后进行分类。
2. 神经网络-多层神经网络：深度学习。
3. 弱人工智能和强AI。
4. 计算机视觉：
   1. 核
   2. 卷积神经网络
5. 自然语言处理
   1. 知识图谱：处理实体的关系，给AI“理解”。 
   2. 语音识别：随着计算性能的提高以及深度学习的兴起，识别的词语和能力都大幅增强。
   3. 声音合成
6. 机器人
   1. 广义上的机器人：现实中的具备“劳动”能力的机器。古代很多自动机器也被称为“机器人”。
   2. 工业机器人带动了机器人行业的繁荣发展。当然，那时候的机器人只有简单的逻辑，具备了一定的负反馈控制能力，后来PID等控制方法出现，但是只能按照流程行动。
      1. PID另一种理解：是对被控制量的本身、积分、导数进行控制的方法，后两者的目标都是到0，第一个参数控制了接近目标的力道，第二个目标控制了误差的稳定，最后一个控制了曲线的平滑。
   3. 机器人的道德伦理
7. 计算机心理学：交互设计中需要重点考虑，计算机与人的接口需要考虑到人的易用易懂。
   1. 让机器人”更懂人类“。
8. 教育科技
9. 计算机的未来：计算无处不在，愿科技让生活更加美好。
   1. 智能科技的失控性发展称转折为：奇点。
   2. 人工智能的意义永远在于”将人类从重复性劳动中解放，从而创造自由意志与生命的更多可能。“当然，短期的失业也是一个严重的问题。
