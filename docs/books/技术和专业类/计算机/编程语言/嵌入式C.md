# 嵌入式C语言自我修养

## Chapter1 工欲善其事必先利其器

在Linux环境下，掌握Vim、GCC、make、Git等工具。

1. apt-get是一种Ubuntu中独有的安装包管理工具，能够安装、卸载安装包;update是用来扫描软件源服务器，upgrade是一次性把所有的包更新到最新的版本。

> **sudo apt-get update**
>
> 　　apt-get update命令会扫描每一个软件源服务器，并为该服务器所具有软件包资源建立索引文件，存放在本地的/var/lib/apt/lists/目录中。 使用apt-get执行安装、更新操作时，都将依据这些索引文件，向软件源服务器申请资源。因此，在计算机设备空闲时，经常使用“apt-get update”命令刷新软件源，是一个好的习惯
>
> **sudo apt-get upgrade**
>
> 　　将系统中的所有软件包一次性升级到最新版本，可以很方便的完成在相同版本号的发行版中更新软件包。在依赖关系检查后，命令列出了目前所有需要升级的软件包，在得到用户确认后，便开始更新软件包的下载和安装。当然，apt- get upgrade命令会在最后以合理的次序，安装本次更新的软件包。系统更新需要用户等待一段时间。

2. 换源：参考博客：[ubuntu换镜像源](https://blog.csdn.net/frighting_ing/article/details/122688413)

> **方法一：直接命令行操作文件**
>
> 清华源的使用指南[ubuntu | 镜像站使用帮助 | 清华大学开源软件镜像站 | Tsinghua Open Source Mirror](https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/)
>
> **方法二：图形化界面配置源文件**



### 码编辑工具：Vim

相对于VS、Eclipse这样的集成IDE，Vim最大的特点在于轻量与快捷，并且脱离了鼠标。

1. 安装Vim：apt-get命令，这个命令只在Ubuntu中才能奏效；
2. Vim的操作：已经有经验了，这部分简单过一下就行，其他的内容留在实践中慢慢熟悉吧。
   1. 五个模式：分别是普通、编辑、：进入的命令行模式、v进入的可视化（框选）模式、替换模式（r选中的字符可以直接单个替换）
3. Vim配置：
   1. 先用vim --version寻找配置文件的路径，找到vimrc文件进入配置。
   2. 似乎有很多这个名字的文件，对应的是不同的用户的配置。
   3. 在这个文件中使用set配置文件，这种做法和直接在vim中使用`:set  XX`命令是一样的效果。
      1. 网上可以找到一些好看的插件和Vim工具配置方案，可以直接拉过来使用。
      2. 安装插件的方法就是在/.vim/plugin下防止xx.vim格式的插件复制到这个目录下。然后相关的插件配置就可以在vimrc中使用了。
4. Vim按键的映射：`:map`命令和它的衍生命令可以查找不同模式下的快捷键。在配置文件中也可以在配置文件中进行快捷键的设定。

- 回头网上找一个方法来配置一下vim

### 程序编译工具：make

1. IDE编译C程序的过程是使用了很多的编译器合集，编译过程被IDE软件一步解决了。
2. 安装gcc（C编译工具）。然后就可以正常使用GCC对程序进行编译了。
   1. 如果只需要程序的链接、预处理可以增加命令来实现。
3. 对于大量的c文件，使用make命令一起编译。
   1. make的作用是根据makefile中定义的编译规则把所有符合要求的路径下的C文件集体编译。感觉有点像“自动执行Makefile中的编译命令”的命令。
   2. 命令行开头必须使用Tab（不是空格的Tab）作为开始。
   3. 一般来说就是后两步生成编译的中间文件，第一步整体进行编译，产出结果。目标只是一个名称，这个名称必须与实际上的命令行产出结果一致，编译才能够通过。
   4. Makefile的格式是目标依赖加命令，命令中还是gcc编译器没有改变。直接在Makefile下输入make命令就可以了。

### 代码管理工具：Git

Git是一个版本管理的工具，是不需要联网的，它通过命令行的方式交互，能够管理和记录本地仓库的修改历史。Github则是一个基于Git的在线分布式仓库管理网站，在Git的基础上创造出了分支等一系列的便捷操作。

Git正是Linux的作者Linus开发出的一种分布式代码管理仓库。

需要连接Github则需要生成SSH密钥并在Github上添加。

更加详细的操作细节和玩法可以参考另外一本书《Github入门实践》。



## Chapter2 计算机体系结构与CPU工作原理

### 从沙砾到芯片

1. Si硅，是晶体管芯片的主要材料，晶体硅的提纯需要从二氧化硅中进行还原，产出多晶硅，然后融化后进行“生长”凝结，获得硅棒形态的单晶硅。贵帮切片生成晶圆，然后设计的模拟和数字电路就会刻印在晶圆上：如今可以达到纳米级别的刻印，当然这需要光刻机。

   1. 芯片进一步被切割、封装、引出管脚，然后进入市场。

2. 芯片的底层原理，实际上就是半导体物理学的范畴，如何用最微观的层面上去实现出所谓的“电容”“电感”“CMOS”等元器件，并通过多层结构压缩在芯片上，这就是芯片设计者所需要考虑的问题。

   1. 半导体的基础还是PN结，Si元素最外层的自由电子和空穴之间形成的P型和N型之分——可以这么认为，PN型半导体虽然没有极性，但是分别表现出了“容易出现空穴/自由电子，因此会从周围夺取/释放电子”的特性——因此二者的组合就发生了自然而然的电子流动，直到生成了一个内建电场抵消了这种“特性”，阻止电流流动的电场和电子扩散的相互平衡，就最终形成了一个稳定PN节。当外部电场削弱内部内建电场时，电子加强扩散行程电流，反过来加强了内建电场则会进一步阻止电流的流动。
   2. MOSFET、三极管也是基于类似的原理设计——电力电子技术、模拟电路中可以看到。
   3. PN节在芯片上的制作最重要的步骤是离子注入和光刻环节。
      1. 光刻（光学曝光），是指利用特定波长的光进行辐照，将掩膜板上的图形转移到光刻胶上的过程。所用的原理和胶片相机类似，掩膜板由透明基板和遮光膜组成。
         1. 电路图需要保存在掩膜版上，然后覆盖在光刻胶（具有感光溶解的特性）上，经过紫外线的照射以及化学药品的清洗，就能留下电路图形。
      2. 被溶解掉的部分称为“掺杂窗口”，顾名思义，就是会根据需要对这些窗口中注入不同的离子（相当于是在硅晶的衬底上“造房子”），掺杂三价或五价的元素。经过高温的注入，硅的表面的窗口处出现了一个特殊的区域，相当于是一个“元器件”。而连接这些元器件的电路“导线”则是通过类似的方法“架高架”，在元器件的上层生成立体的金属路径做出来的，
         1. 经过这一步，硅晶的衬底上就能够形成主要由PN节构成的各种元器件。
         2. 每一层都需要重复这一操作，制作对应的掩模版，生成3D迷宫式的立体结构。最后经过一些特殊方法去除光刻胶，在底层留下掺杂以及在表面留下金属化的电路。
         2. 最后硅的底层
      3. 真正精密度要求高的其实就是“感光胶片”的形成，如何精确的把电路图投影到光刻胶上就是光刻机的全部工作范围。
         1. 目前世界范围内仅有ASML一家具备光刻机的生产能力。
         1. 光掩模不需要芯片那么小，只用投影到芯片的尺寸就行了，光的好处是能够通过镜面的聚焦去随意改变投影的大小。
   4. 芯片的封装：给芯片电路增加一个外壳，引出管脚，让其能够被焊接在电路中。
      1. 封装讲究的是“标准化”，不同的电路要能够节省体积的同时便于电路设计和焊接，就必须按照标准进行引脚的设置和封装。
      2. 测试


### CPU是怎么设计出来的

1. 图灵机：一种假象的模型机器，具备了基本的计算机思想。
2. CPU的原理是以控制单元为中心。这里计组以及导论中有过更加详细的介绍。
   1. 所谓的程序，就是指令集的不同组合。
3. CPU设计流程：模拟、数字、数模混合。数字设计的基本流程如下
   1. 设计芯片规格
   2. HDL代码实现：前端仿真（验证芯片的逻辑功能是否正确）——通过EDA软件转换成逻辑门电路
   3. 仿真验证
   4. 后端设计：物理版图，类比从”电路图“到”PCB“，主要设计位置、走线以及一些设计规则。
4. 计算机体系结构：冯诺依曼架构（熟悉的五大部分）、哈弗架构（主要特点是程序和数据分开存储，8051用的就是这种）、混合架构（比如现代的CPU通常使用了程序缓存和数据缓存分开的结构，来提升程序运行的效率）
5. Cache机制
   1. Cache物理层面上SRAM，实现层面上就是保存最近访问过的地址和数据，当里面的地址被调用的时候能够快速给出数据，或者写入Cache。Cache与内存出现不一致的地方，称为”Dirty Bits“，将会按照Cache中的内容对内存进行更新。
   2. 一级、二级Cache的出现：Cache未命中并且已经满了，此时将会非常耗时间，另外，过大的Cache成本增大，发热和复杂度也大大提高。所以需要出现多个Cache，二级Cache不需要一级Cache的速度，但是能够极大程度上提高计算机的性能。另外，多核计算机中可能还会出现三级Cahce。
   3. 当然，对于一些低功耗并且对于性能要求不是太高的CPU而言，Cache是可以省略的。
6. 流水线
   1. 顾名思义，每一条指令对应了 取址、译码、执行 三个步骤，而这三个步骤是在三个部分上完成的，每次等待全部都完成过于浪费效率，所以就是用流水线技术。具体的可以参考计组中的知识。
   2. 超流水线：流水线怎么提高效率？答案是增加步骤，减少每一步的时间，流水线会被最慢的一道工序拖慢。
      1. CPU中同步使用的是时钟，每个时钟周期完成一道工序。
      2. 现代的处理器一般能够有10级以上甚至二三十级的流水线，通过减少每一步的执行时间，把原来的步骤细分为更加小的步骤，从而提升机器的整体效率。这就是”超流水线“。
   3. 流水线冒险：结构、数据、控制
      1. 所谓冒险就是”冲突“，两个指令同时需要同一个硬件资源。比如，当程序中出现跳转类的，需要流水线停下来等待，那么流水线上预先取的下一个指令就需要丢掉了。
      2. 第一种方法是让流水线此时停顿，等待上一个命令完成，让出资源再开启下一个任务。
         1. 流水线很深的情况下，等待耗费的时钟周期也会变长。
         2. 所以才有了”猜测“。
      3. 或者使用分支预测，
         1. CPU去判断分支的可能型，提前做好预取。
         2. CPU的预取是提高性能的关键技术。
      4. 乱序执行：简单来说，就是CPU重新排列指令的顺序，来避开寄存器使用的冲突。
         1. 当然，前提是指令之间不存在相关性，前后调换并不会影响处理的结果
      5. SIMD和NEON
         1. SIMD通过单指令多数据运算，在指令的层面实现了数据的并行访问，适合图像处理。
            1. 这种指令随着计算机的发展不断的拓展，后来出现了MMX，SSE，FMA等各种指令集。
         2. NEON是适用于Cortex-A和-R52这种移动设备处理器的指令集。
      6. 单发射和多发射
         1. 多发射处理器就是分配工作给不同的运算单元，一个时钟周期内多个运算，不让不同的运算单元空闲。
         2. 静态发射是在编译阶段把可以并行的指令打包。这种方式，称为VIEW架构，它不需要硬件支持。
         3. SuperScalar则是另外一种，它则需要硬件支持。
   4. 多核CPU
      1. 单核处理器：瓶颈在于单核提高性能的同时也会提高功耗，远远比不上使用多个处理器运算来的划算。
      2. 如何连接？
         1. 片上多核互连技术——总线型根据连接方法分为了星型连接和总线连接。
         2. 交叉开关型弥补了总线型只能允许一对设备通信的缺点。缺点是功耗比较高。
         3. RingBus结构结合了总线型和开关型连接，目前比较流行的一种是二维Mesh网络。
      3. big.LITTLE结构
         1. 多个Core一起上阵可以提升效率，但是同时也会增加功耗。
         1. LITTLE作用就是通过簇既能够保证通讯的一致性，也能够根据CPU负载去实际调用CPU。
      4. 超线程技术HT
         1. 超线程就是充分利用某一线程上限制的硬件资源，让给另外一个线程使用。（简单理解就是华罗庚烧水的问题）
         1. 超线程并没有“多线程”，它只是同一个线程充分利用了Core上的共享资源。这种技术需要软硬件的配套支持。
      5. 多核CPU性能并不是完全的由核的数量来决定，更重要的是需要软件配合，能够做到更多的核参与到运算中去，越多的并行代码才能越充分的调用多核处理器的优势。
         1. 另外，大型游戏一般注重主频的单核性能，如果不采用优化或者优化稀烂，“一核工作，八核围观”，可能多核的效果反而比不上少一点的核。

### 后摩尔的时代：异构计算

1. 异构计算就是在SoC芯片内部集成不同架构的Core，比如DSP、GPU这种专门处理各种运算的单元，通过CPU的协同，分配任务进行不同类型的运算。
   1. System on Chip，
2. 异构计算核心
   1. GPU：图形处理单元。它没有CPU那样的复杂控制单元核Cache，但是却又成千上万个核心。虽然无法处理复杂的逻辑程序，却能够通过强大的并行处理能力，具备了优秀的计算能力。
   2. DSP：数字信号处理，主要优势在于指令的优化（比如单周期的加减、逆序加减、块重复），具有专门的乘法器，在做诸如卷积运算的时候速度非常快。
   3. FPGA：现场可编程门阵列， 不依赖于门电路，也不需要编译器，能够硬件上直接跑一个功能，通常和CPU结合协同工作。
   4. TPU：张量处理器，Google专门为深层神经网络的运算专门研发。
   5. NPU：神经网络处理器，指令层面直接执行大规模的神经网络运算。
      1. ANN，人工神经网络，是一个数据结构的通用模型，通过复杂的连接建立认知。
3. 对于异构计算单元，通常使用浮点运算能力来衡量处理器的运算能力。
   1. 后摩尔时代，摩尔定律失效，各大厂商开始异构计算，提升处理器的性能。

### 总线与地址

这一部分本书讲解并不详细，可以参考计算机组成去更加全面的了解这两个概念。

1. 地址与总线，是计算机内存访问的最重要概念，可以说弄懂了这两个东西就等同于弄明白了计算机的内存。
2. 地址本质是“总线上包含的信号”，总线宽度一定程度上决定了能够访问地址的数量，也就相当于决定了内存的大小。
3. 总线是CPU和硬件之间的路径，不同类型的信号从不同的总线经过，总线因此被分为地址、数据和控制总线。
   1. 其中内存、显卡等挂载在PCI高速总线，而串口、键盘等挂载在低速总线，高低速，高速和CPU之间分别通过南北桥进行连接。桥的含义就是统一工作时序。
4. 总线编址方式：统一编址

### 指令集与微架构

1. 不同的指令集不可能互相兼容，指令集也必须和硬件架构紧密的结合。

   1. 图灵机的基本思想：任何复杂的运算可以被分解为有限的步骤，这一点也是所谓“编程”最核心的一种理念。

   2. > 什么是可编程?编程从来不是"自由的",就像是积木拼搭不了没有的元器件,而编程也无法跳脱出ISA指令集的桎梏。
      >
      > 但是就像积木一样，有限的元件通过反复、组合，形成了无限的可能，因此编程也是“自由的”。
      >
      > 什么是可编程？积木为什么能够拼搭？这两个问题回答或许是一样的。
      >
      > 抽象。

   3. 指令集是一种标准规范，编译器厂商和CPU厂商在设计编译器和芯片的时候，也需要使用指令集中的指令格式，为的是不同的机器上能够把高级语言编译称为指令集中的命令。

      1. 它规定了指令的分发、预取、解码，地址的格式，操作数的类型，寄存器等等。
      2. 指令集一直在扩充。

   4. 微架构：处理器架构，常见的如Cortex-A这种。或者可以叫做“处理器的内核”。

      1. 是为了配套指令集而设计的电路，一套指令集可以设计出多种架构，然后CPU内核搭配设计出不同的SoC芯片。
      2. 目前能够使用X86指令集设计微架构（芯片内核）的公司只有，Intel、AMD、兆芯三家。
      3. ARM指令集则是开放授权的，麒麟、骁龙、苹果A11等都是ARM。这些芯片购买授权，使用了ARM的Cortex系列的内核电路或者直接购买了ARM的处理器，然后设计SoC芯片。
      4. 汇编语言是指令集的助记符号。
         1. 一套指令集一般对应了一套汇编语言，因此其实只需要学习x86和ARM的就可以了。





## Chapter3 ARM体系结构和汇编语言

### ARM指令集

1. ARM指令集因为其开源特性，流传广泛，嵌入式学习通常会以ARM入手。
2. 指令集的分裂：CISC复杂指令集、RISC精简指令集、EPIC显式并行指令集、VLIW超长指令字指令集。
   1. ARM属于RISC但是也具备了一些自己的特色。ARM具有多种工作模式和权限管理，它的寄存器分为通用寄存器和专用寄存器，每一种工作模式下，都有一个单独的程序状态保存寄存器。
3. 一个完整的ARM指令集由操作码+操作数组成，操作码是一定有的，其它则有时候可以没有。
   1. 储存访问指令属于RISC，采用的是典型的加载/储存体系结构，需要对内存中的数据进行操作时，必须Load/Save，借助寄存器来完成。
      1. 常用的是LDR/STR、LDM/STM两对指令，是从内存中读取、向内存中储存（后者批量读写）的指令。
      2. LDM和STM通常和内存堆栈结构组合使用。
   2. 数据传送指令：MOV，用于将数据在寄存器之间传输。
   3. 算术逻辑运算指令：包括了加减乘除、与或非、异或、清除
      1. 2和3的运算，既可以是两个寄存器运算，也可以是一个寄存器和一个立即数之间进行运算。
      2. #constant就是立即数的格式。立即数可以使用移位操作。
   4. 比较指令：CMP，
      1. 运算结果通过寄存器的NZCV四位去展示。来表示是否相等，或者大小关系，是否溢出等。
   5. 条件执行指令：无条件跳转+条件判断就能够组曾不同的各种条件指令
   6. 跳转指令：B开头的一系列指令，跳转到Label处。
4. ARM寻址方式
   1. 寄存器寻址：使用寄存器的名字Rn
   2. 立即数寻址：使用#constant的立即数来直接表示地址，如#0xff
   3. 寄存器偏移寻址：寄存器+左右移位操作，可以从某个特定的地址或者寄存器出发寻找下一个寄存器的值。
   4. 寄存器间接寻址：寄存器中保存内存中的地址
   5. 基址寻址：间接寻址，就是把偏移寻址得到的地址储存到一个寄存器中，再通过这个新地址访问内存，一般用在查表、数组访问等场景
   6. 多寄存器寻址：一次可以传输多个寄存器的值
   7. 相对寻址：也是便宜寻址的一种形式。
5. ARM伪指令：伪指令不存在于指令集中，但是厂商自定义的一些辅助指令——有点像预编译指令。
   1. LDR、ADR


### ARM汇编程序设计

1. 程序格式：以段section为单位进行组织的。它的定义用AREA进行。
2. 符号与标号
3. 伪操作

### C语言和汇编语言混合编程

为什么需要？在比如系统boot过程中，以及C语言中需要提升性能的场合，就需要C语言和汇编语言混合使用。

1. ATPCS规则：ARM-Thumb Procedure Call Standard

   1. 定义了ARM子程序调用的基本规则和堆栈的使用约定等。

2. 在C语言中内嵌汇编代码：__asm关键字

   ```C
   __asm
   {
   	汇编代码
   }
   ```

   只需要这样使用，就可以直接在C语言中内嵌汇编语言。并且这个语块可以被一些修饰符修饰。

3. 在汇编程序中调用C语言

   1. 可以使用BL指令进行跳转，在汇编中调用到C的函数。

### GUN ARM汇编语言

ARM的编译器一般可以分为：IDE内部集成的ARM编译器，如Keil MDK，另外一种则是开源的如GUN GCC for ARM。

1. 编译器是什么？

   编译器包含了一套工具，编译器、汇编器、链接器、二进制转化工具、库打包工具、调试工具、库/头文件。

   ARM的编译器开发遵循同一套指令集标准，因此不同编译器的程序可以在同一台机器上运行。

2. 伪操作

3. 基本数据格式

4. 数据定义

5. Linux中可以 -S编译成.s汇编语言程序把C程序转化成汇编程序。



## 程序的编译、链接、安装和运行

嵌入式工程师必须考虑程序设备底层的知识，代码运行在何处，烧录到哪里，如何执行等问题。编译原理方面的推荐阅读《程序员的自我修养》、虎书、鲸书、龙书等经典教材。本书主要是梳理整个编译的过程。

###  从源程序到二进制文件

1. 使用readlf获取文件的头部信息，通过这种方式，可以获得这个文件有多少section headers,由此可以窥探到：一个可执行文件由一系列section组成，用来储存比如data、代码等信息。
2. 编译的第一步，就是将C语言中定义的函数、变量挑出并加以分类，放置在不同的section中。
3. 便器的起点是C源文件，经过预处理，生成.i；经过编译器，生成.s；经过汇编生成.o；最后几个文件和库文件通过连接器生成目标的文件。
   1. 可执行文件是目标文件的一种，目标文件也可以是其它的形式

### 流程

1. 预处理：就是在编译源程序之前，先处理预处理命令，展开头文件和宏，删除注释等工作都在这一步完成。
2. 编译：从高级语言到低级语言，通常分为六步骤：词法分析——每一句代码从左到右一个个分解，变成token单元；语法分析——对token序列进行解析，生成树状的结构；之后的语义分析——对语序做出语法检查；之后生成中间代码——输出了临时代码，一般有三地址码、P-代码等；汇编代码生成——尝试使用ARM汇编实现中间代码；最后生成目标代码——根据指令集，把汇编转化成二进制指令。产出的结果是.o文件。
3. 链接：
   1. 分段组装：不同代码段的section进行分解组装
   2. 符号决议：解决多个文件中的符号冲突问题。
   3. 重定位

### 程序的安装

1. 本质：就是将一个可执行文件安装到ROM中的过程，将这个可执行文件和动态共享库复制到指定的安装目录下，并把这些位置告诉操作系统，在需要执行软件的时候，操作系统就能够将其加载到内存中去。
2. dpkg命令可以在Linux中将可执行文件打包成安装包。安装包可以上传到网上，被下载，为了安全性，Ubuntu在用了apt-get作为包管理工具，第三方库被验证后才能够上传到服务器上。
3. Windows的安装包制作用的是压缩，选择高级自解压方式就可以了。





# 看不下去了，未来再看。



## 23/4/22讲座

1. static是一种本地化的手段——用老师的比喻来说，static是诸侯的私人物品，无法被外部c程序调用。

2. extern是一种外部调用函数声明——用比喻“外来的和尚会念经“。当然无法调用static的函数。

3. const无法更改变量——安全。const限定的变量会编译到flash中，节省ram空间。

   0. 相比宏，const常量。只要两个一起记忆就很好记忆了。

   1. int *const a是指向常量指针，即指向确定地址，指向的变量值可以修改。
   2. const int *p是指向常量的指针，指向不可以变的常量，本身可以指向其它的常量。

4. auto的本质是把变量存放到栈中，

5. volatile

   1. —编译器会偷懒，可能会在优化中，会改变代码的逻辑，或者有时候多线程会改变寄存器中的变量值。
   2. 加入这个修饰表明这个变量容易变化，必须从内存中读取。

6. 头文件：

   1. 重复包含问题：#include本质是会把整个文件复制进入当前文件的。因此才有重复包含的问题。才使用#ifndef去限定

   > 工程中，由于复杂的文件包含关系，需要很多的预编译去检测是否已经定义的问题

7. 使用宏函数足额实现高效的调用

   1. 甚至可以两个宏函数组合形成更加高级的函数

8. 利用函数指针进行函数的动态执行

   1. 函数的实际内存占用长度是一样的
   2. 主要可以用来做整体代码的模块化
   3. hook函数：函数指针作为一个“原型”——可以类比C++里的虚拟类的定义，通过函数指针来实现类似虚拟类的部分。

9. 内存分区：

   1. 堆区：malloc的部分
   2. 栈区：程序调用关系（可以去看看CSAPP），栈会溢出的。
   3. 静态区：全局变量，静态局部变量（static）

10. 结构体分配：会一定程度上遵循对齐原则，所以有时候struct中的顺序有时候会影响sizeof

    1. 可以使用#pragma pack(x)可以强制让内存中最多出现x个空。
