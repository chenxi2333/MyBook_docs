> 主要是看书和CS188和CS50.3网课配套观看阅读

# PART 1 人工智能基础
## Chapter 1 Introduction

### 1.1 What is AI

- 客观判断标准：Fidelity to human(类似于人类) Or Rationality（合乎理性）——do the Right Things 
   - 主观判断标准: Internal thought and reasoning Or External characterization?
- 于是就有了4种定义标准：Thinking Humanly 、Acting Humanly、Thinking rationally、Acting rationally.

#### 1.1.1 Acting Humanly：Turning Test图灵测试

严格的图灵测试需要计算机具备以下基本能力：

- 自然语言处理 natural language processing
- 知识图谱knowledge representation:store what it knows or hears
- 推理automated reasoning：answer question and draw new conclusions
- 机器学习machine learning:adpt to new circumstances and to detect and extrapolate patterns

total Turning Test：需要在基础上做到交互与行为，这就需要计算机具备：

- Computer vision：计算机视觉
- robotics：机器人学

而以上六个学科就是AI的基本组成。图灵测试只是一种“测试标准”，而不是研究的目标或者说方向。

#### 1.1.2 Thinking Humanly：The cognitive modeling approach

人类是怎么思考的？我们一般可以通过三种方法去窥探人类自己的思维：

- introspection内省
- psychological experiments心理实验
- brain imaging大脑呈像

congnitive science结合计算机模型与心理学实验，试图对人类的认知模型进行精准的认知和建模。从而发展出了一门复杂的学科。
现代的AI和认知科学互相丰富，将比如神经模型建立在计算机中，才有了计算机视觉；如今能够通过神经网络和机器学习的方法分析人的心理活动以及潜台词，这种技术也能极大程度推进认知科学的研究。

#### 1.1.3 Thinking rationally:The"Laws of thought" approach

逻辑学，诞生自苏格拉底的三段论，在19世纪，逻辑学发展出了数学语言描述——这一点也是二进制计算机诞生的基础。将任何问题以逻辑的语言描述然后加以执行，正式计算机算法求解问题的最底层逻辑。
然而逻辑学求解问题的前提是确定性——这一点在现实世界中难以达成。这一点障碍已经随着概率论的发展逐渐跨越。虽然理论上概率论能够对世界进行合理的建模、预测、理解。但是仅仅如此是无法建立智能的行为——Rational thought , by itself, is not enough。

#### 1.1.4 Acting rationally：The rational agent approach

Def：An Agent is just something that acts.Computer agents are excepted to do more:operate autonomously,perceive their environment...
A rational agent is one that acts so as to achieve the best outcome or, when there is uncertainty, the best excepted outcome.
所谓的Agent就是计算机的理性行为——以“最优”为目标的行为就是“合理”的行为。不同于指令程序，Agent能够自己判断应该如何去做并自动在不同的环境下完成指定的任务。
上一节中所述的计算机理性判断是Rational Agent的重要一环，计算机只有先对问题、环境进行理性的分析之后才能找到“最优解”。图灵测试中的种种能力也是Rational Agent所必需的，为的就是能够适应各种环境、各类问题，并能够通过只是图谱找到最优的方法。“学以致用”——于机器人而言同样如此，学习是为了高效的完成任务。
Rational Agent是AI各个领域的主流，它覆盖了Rational thinking 并且能够推动科学的发展。它被数学充分明确的定义，并且能够被一点点的被人们实现。由人类定义何为“正确”的目标，告诉计算机什么是“正确”，再让计算机学习并建立agent，去做“正确”的事情——这就是AI的标准模型standard model。
复杂环境中往往不存在最优，因此我们往往会从最优解的角度出发，试图给复杂问题找到一个合理的解——这就是limited rationality issue。

#### 1.1.5 Beneficial machines

stadard model的前提是“We will supply a fully specified objective to the machine”——我们给定了一个清晰明确的目标。如果目标不单一、不明确，这种标准模型并不适合。
对于比如寻找最短路径、下棋这样的明确目标的任务中，标准模型能够适用，但是比如说自动驾驶这样的，需要考虑时间效率、安全性、各种突发路况、乘客舒适度等多个因素的问题，这些问题没办法预先设定，标准模型则无法适用。后者这样的问题称为“value alignment problem”（价值定位问题）。
必须要能保证机器的“价值观”与人类的一致——这一点其实相当难以定义描述，因为人类无法预测智能机器人会以何种手段追求某个目标。比如说在下棋比赛中，计算机得出的为了达成“赢”这一目标，最有效率的方法是作弊或者干掉对方棋手，然后执行了——这个机器并非不“智能”或者说“不道德”，它可能是过于“智能”了，它的行为完全符合它的“Objective”，也实现了“最有效率的赢下比赛”这一目标。
实验室模拟环境下很容易就能修正机器错误的目标，但是现实中并不可行，因为现实中一旦生产中一旦目标错误，就会产生严重的错误——越是智能，反而负面影响越大。
当然，计算机为了达成一个目标不择手段当然也不是我们想要的。我们需要的是机器完成我们的目标，为此，我们不需要让机器“完全”明白我们的目标，让它只需要做它该做的事情，这样让它们在我们的控制之下。我们希望能够保证它的安全。

### 1.2 The Foundations of Artificial Intelligence

人工智能的历史可以围绕几个问题去展开。

#### 1.2.1 Philosophy

- 形式的规则可以得出有效的结论吗？
- 思维如何从大脑中诞生的？
- 知识从何而来？又如何引导行为？
- 如何定义“正确的行为”？

关于形式规则，亚里士多德的三段论是形式规则的开端，让人们得以从前提推导出结论；达芬奇设计了计算器的原型，后来逐步发展出了计算的工具。Thomas Hobbes的著作《利维坦》中，提出了一种“Artificial Animal”的概念生物。
关于物质和意识的问题，笛卡尔二元论认为思维脱离于物质的范畴，而唯物主义者认为思维建立于大脑的物质基础之上。
关于知识的来源，经验主义者认为知识建立于经验和感觉，有人则认为知识来源于推理和归纳。Logical positivism则是把这两者结合。此外还有confirmation theory等观点。
关于认知的知识和实际的行动，这一点的认知对于AI来说是很重要的，人工智能要求能够把推理转化成为行动。我们必须认识我们自己的正确行为是如何被我们认知的知识影响的，我们才能够去让人工智能做出正确的行为。亚里士多德的观点是我们的行为出于理性逻辑——人们为了实现一个目标，做出理性判断，然后主导他们的行为——这一观点也是AI理论的前几十年发展的基础。
但是实际生活中这样的纯粹理性的决策并不会出现，一个结果的主观价值可能比客观的价值更加重要。对于道德、法律政策这样的公众决策，考虑到不同主体的主观价值利益同样重要，这些决策需要能代表大多数人的利益。在这基础上诞生了一种“功利主义”——天下熙熙皆为利来，天下往往皆为利往，人会选择利益最大化的行为这样的观点。
与之相对的则有义务论者，认为正确的行为并非以结果论而是被规定的——有诸如法律或者别的形式的，明确的规定了正确与错误的界限。将规则认定为第一判准，这也是人工智能中所指的“正确的行为”。

#### 1.2.2 Mathematics

- 我们如何能够形式化的去推理？
- 什么是可以被计算的？
- 如何使用不确定的信息进行推理？

形式化的逻辑古代哲学家就有所研究，这也是后来人工智能诞生的根基。概率论可以视为信息不确定情况下的广义逻辑，统计学的诞生很大程度上帮助我们研究不确定的事件。

但是同时，哥德尔的不完全性定理表明，在PeanoArithmetic中，必然存在一些无法被证明的真实命题。这就表明并不是全部的问题都是可以通过算法实现的，即有些问题是不具备“可计算性”的（computable—capable of being computed by an effective procedure）。

另外，在实际计算中，算法的易处理性（tractability）更加重要，我们需要更加高效的去解决包含了大量数据的问题。NP完全性理论（NP-completeness）为分析问题的tractability提供了理论基础，计算机的速度也越来越快，但是我们必须认识到智能系统的缺陷，并且谨慎使用它有限的计算资源。

> Put crudely, the world is an extremely large problem instance!


#### 1.2.3 Economics经济学

经济学正式开始于《国富论》的发表，后来加入了概率形成了“决策论（decision theory）”。对于更加微观的个体，又诞生了“博弈论（game theory）”。二战中更是发展出了“运筹学operation search”，将一系列的决策过程形式化，称为”马尔可夫决策过程“。

虽然与AI的发展路线不尽相同，但是这些工作对于理性智能体的改编做出了很大的共享。例如人工智能中设计多个智能体的决策称为“multiagent system”，就与博弈论相类似。
#### 1.2.4 Neuroscience 神经科学
神经科学研究人的思维如何产生。前言已经开始研究脑机接口，开始揭秘神经系统的奥妙。
计算机的计算能力未来将可以超过大脑，有望成功产生智能。
#### 其它

- 心理学：人类和动物是如何思考的？认知心理学。
- 计算机科学：提供计算的加速。
- 控制理论和控制论：智能和反馈控制模型的异曲同工之妙
- 语言学：自然语言处理领域
### 1.3 History
人工智能诞生之后的几十年，在很多简单初级的问题上取得了不错的效果，但是随着问题复杂化，这些算法无一例外的都遭受到的挫折。在人工智能诞生的前几十年之内，所采用的“weak method”很难具有复杂问题的普适性。
后来研究专家系统，发展反向传播，概率推理和机器学习方法引入让人工智能重新受到重视。如今互联网带来的大数据更是给人工智能的发展和应用提供了土壤；算法方面，深度学习，使用多层简单可调整的机器学习方法。

### 1.4 人工智能的应用和风险

- 应用：自动驾驶、机器人、翻译、语音识别、推荐系统、博弈（游戏）、图像理解、医学、气候科学。
- 风险：致命性武器、有偏决策（数据偏见）、就业影响、安全关键的应用、监视。
   - 迈达斯国王问题：人类无法有效的“解释”自己想要的明确目标。
- 收益：人类级别的人工智能，能够代替人类从事简单重复的劳动。
## Chapter 2    Agent
### 2.1 Agent and Environment

- 任何通过传感器感知环境并且通过执行器作用于该环境的事物都可以视为智能体。
   - Agent两个核心要素：Sensor和Actuator
- Agent就是人工智能的主体。
- 环境的本质就是人工智能需要解决的问题。一个人工智能我们可以通过PEAS来进行描述——性能、环境、执行器、感知器。
   - 任务环境的属性决定了任务的复杂性——部分可观测（智能体的感知器不能够每时每刻的察觉到环境的改变）、多智能体、非确定（环境并不能完全由智能体的行为控制，需要不断的去感知）、连续的、序贯的（相对于回合的）、动态的且未知的（环境未知）。
- 智能体=架构+程序。
   - 程序的输入来自感知器输出则是返回到执行器的动作
   - 四种基本的程序类型：简单反射（类似条件-反射）、基于模型（能够通过模型去思考和应对环境的变化）、基于目标（能够预测动作的后果并且有一个既定的目标）、基于效用（在达成目标之上加入了评分）
   - 学习型智能体：为智能体加入性能评估，通过给予奖励和惩罚的标准，让智能体的部分元素可以通过学习去改进和优化。

# PART 2 问题求解
## Chapter 3 搜索
### 3.1 问题求解智能体

- 基础概念：state、action、transition model、action cost function
- 搜索问题就是：如何通过行动从状态空间中的初始状态（initial state）达到目标（goal state）。
   - 转移模型为行动提供了数学描述。
   - 一个动作序列形成一条路径，能顺利从起始到目标的路径就是解，代价最小的解就是最优解。
- 搜索问题的模型是现实问题中提取出的，因此具备很大的研究价值。
### 3.3 搜索算法

- 首先需要把搜索的状态图转化成为一个搜索树，通过树的结构去寻找解。
   - 树的最下层是"边界"frointer，即尚未被expand拓展的状态节点，拓展过的则称为"内部"，外部就是尚未到达的点。
- 不同的搜索算法之间的主要区别其实在于"优先探索Expand哪一个点"，这取决于边界state的队列使用了哪一种。
   - FIFO队列最先弹出先添加的点，广度优先；FILO队列先弹出后添加的点，深度优先；
   - 最佳优先搜索：这个方法就是拓展过程中给每个到达过的点标记上走过来的消耗，拓展代价最小的节点。
   - 已经到达的节点可以使用无序列表如哈希表这样的查找表就可以了
- 冗余路径：存在非常多的类似"环路"这样重复的路径，搜索问题中，"前车之鉴，后车之师"。
   - 我们可以像最佳优先算法那样，对于每一个节点，只需要保存最佳路径。另外有一些问题中注定不可能出现冗余路径，我们也没必要额外去花费空间存储。还有一种折中方法就是仅仅消除循环或者小循环就可以了。
   - 检查冗余的算法称为图搜索，否则称为树状搜索。
- 算法一般通过：完备性、代价最优性（就是能不能找到解，找到的是不是最优解）以及时空复杂度来评价。
   - 完备性：有限的状态空间中保证可以到达每一个目标状态。无限的状态空间中方式必须是系统的——虽然无法实际走完每一个状态但是能够证明可以达到。
### 3.4 无信息搜索策略

- 无信息搜索不提供有关某个状态与目标状态的接近程度的任何线索。
- 当所有的动作代价相同，我们一般可以采用广度优先算法。采用FIFO的方法把节点压入队列。
   - 这种方法是完备的，并且保证能够找到最优解。但是它的复杂度随着节点数量的增加指数级增长。
- 所有动作的代价不同时候，一般使用Dijkstra算法——一致代价搜索。
   - 这种方法简单来说就是优先拓展代价最小的节点。
- 深度优先探索
   - 完备，但是可能会在环存在的时候出现无限循环的情况。
   - 回溯搜索，是深度优先搜索的一种变体。（第六章会讲）
   - 深度界限：一个图上存在最深的步数——称为“直径”。我们通过设定深度树的下限来“剪枝”。
   - 迭代加深算法：通过一点点的增加深度，可以在深度比较小的时候使用广度优先而随着深度增加，空间不太够用的时候转而使用深度优先。
- 双向搜索，是一种从初始和目标处同时进行搜索，双向奔赴的算法。双向最佳优先搜索是其中的一种方法。
### 3.5 有信息搜索策略

- 有信息搜索，即启发式搜索，我们拥有一定目标位置的信息。
- 贪心最佳优先搜索：
   - 简单来说，如果我们知道距离目标位置的“直线距离”h(n)，那我们可以通过优先拓展直线距离最短的节点来寻找路径。
   - “直线距离”h(n)代表了某个节点到达目标的“代价估计值”。
   - 这种方法并不保证能够找到全局最优解。
- A*搜索：在贪心的基础上使用了新的评估函数f=g+h，其中g是从初始节点到节点n的路径代价，而h则是节点n到达目标的代价估计值。f整体此时就表示了“经过n到目标状态的最优路径的待机估计值”。
   - A*是否能够到达代价最优取决于启发式函数f的选择。F是否具有“可容许（Admissibility）性”以及“一致性”很关键。
   - 第一个性质要求_h*>=h_永远成立。简单来说就是最短距离的估计永远小于等于实际距离。
   - 第二个性质要求：三角形的一条边小于另外两条边之和——三角形的三个点分别表示了“目标节点”“当前节点”以及“某个动作后的下一个节点”。
- 搜索等值线：当启发式函数确定之后，就可以绘制等值线，区分节点的代价。
- 满意搜索：不可容许的启发式函数的A*搜索
   - 加权A*索索，简单来说就是在h前面加上一个权重W。
- 内存受限搜索：A*搜索的主要问题是它对内存的使用比较多。
   - 束搜索：只保留f最优的几个节点，舍弃其它的节点。
   - 迭代加深A*搜索：截断值是以f作为参考，舍弃掉一些f过大的值。
   - 递归最佳优先搜索：它会额外记住一个“倒推值”，并不会记录下全部的f而是记录下“第二最小的值”，以便于能够“回心转意”。
- 双向启发式搜索：双向+A*启发
   - 这个方法并不能保证代价最优或者效率最优。这种方法中，除了需要估计到达目标的直线距离，还需要估计
### 3.6 启发式函数

- 本节中主要讨论启发式函数的准确性问题，以及应该如何在问题中确定启发性函数。
   - 启发性函数重点是能够证明“最短”，“直线距离”。
- 启发性函数越是准确，程序算法的效率越高。
   - 我们通常使用有效分支因子这个变量来估计搜索算法的效率。这个参数越小代表程序效率越高，能够探索更少的节点。
- 从松弛问题出发生成启发式函数：
   - 典型就是移动方块的例子，通过减少限制条件来判断问题的最小解。求出松弛问题中的最优解就可以得到一个可容许的启发式函数。
- 从子问题出发去考虑问题：
   - 通过把问题中某个部分拆下来作为子问题去考虑
- 通过地标生成：
   - 在线地图通常使用这种方法，从顶点中选择一些作为地标点，通过预先的设定捷径，来提高效率。
   - 差分式启发：
- 学习
   - 可以让机器学习去从经验中学习如何预估启发式函数。
   - 更进一步，我们还可以使用机器学习去优化已有的方法，通过组合不同的方法并用机器学习给它们增加权重参数，来研究如何组合能够使启发式函数更加优秀。
## Chapter 4 复杂环境中的搜索
### 局部搜索和最优化算法

- 局部搜索和最优化问题：就是工程优化里讲的内容：梯度下降。
   - 梯度方法在处理岭和平台问题的时候并不能很好的解决。
   - 平台区的解决方法是允许横向移动。
   - 随机梯度上升可以通过概率来解决过早收敛的问题。
   - 另一种是随机初始位置的梯度上升，称为随机重启爬山法。
- 模拟退火算法：完全的随机移动
- 局部束搜索：蚁群搜索方法，从多个不同的位置开始并行搜索，能够共享搜索中得到的信息。
- 进化算法：遗传算法
### 连续空间中的局部搜索

- 连续空间中局部最优化问题一般是高维的，
   - 处理连续空间的最优化方法一种是把连续问题离散化。
   - 其它的方法可以参考工程优化这门课
### 使用非确定性动作的搜索

- 动作的结果是不确定的结果
- 求解需要引入 与或树。
### 部分可观测环境中的搜索

- 无传感器问题，也就是一致性问题求解：
   - 这类问题的解是一个动作序列，而不是条件——有很多这样的问题
   - 有一些方法可以通过一系列动作强迫Agent到达指定状态。
   - 这类问题可以通过大量的构建"信念"，去列举所有的可能性以及计算出如何能保证到达解。
- 部分可观测问题经典案例就是声纳机器人自身定位的问题，通过探测周围的环境能够快速判断出自身的位置信息。
### 在线搜索

- 所谓的在线搜索是指必须在接收到输入时候立刻进行处理计算，不会等待全部输入之后再计算。
   - 典型问题是地图构建问题
- 在线搜索问题：
   - 已知条件：合法动作、每个代价、是否为目标的判断。
   - 在线搜索能够构建地图并找到目标。
   - 难点：死胡同，这个难以避免。根据经验来更新启发式函数是一种避免的方法。
   - 随即游走方法：指数级的时间内可以找到目标。
- 在线搜索中的学习

## Chapter 5 对抗搜索和博弈
本章将讨论竞争环境中，多个智能体具有互相冲突的目标时候如何解决，这样的问题称为对抗搜索问题。典型的问题就是博弈，比如棋类问题。棋类问题相比体育运动，动作比较明确，易于定义。（棋类-电子竞技游戏-现实体育运动）
### 博弈论

- 关于"对手"的处理有三种模式，第一和第二种都是把队友看作是一个整体，或者环境的一部分，这样就可以通过整体性规律或者概率的规律对"对手"进行建模认知，两者都忽略了对手积极反击的事实。
- 第三种则是建立对抗博弈的搜索树。
   - 每一步中，我们可以通过评价函数来评价谁更胜一筹。
